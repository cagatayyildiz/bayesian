{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": false
   },
   "source": [
    "## An Implementation of HMM in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run include/utils.py\n",
    "%matplotlib inline\n",
    "\n",
    "# see https://github.com/kirbs-/hide_code for export issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def predict(A, lp):\n",
    "    lstar = np.max(lp)\n",
    "    return lstar + np.log(np.dot(A,np.exp(lp-lstar)))\n",
    "\n",
    "def postdict(A, lp):\n",
    "    lstar = np.max(lp)\n",
    "    return lstar + np.log(np.dot(np.exp(lp-lstar), A))\n",
    "\n",
    "def update(y, logB, lp):\n",
    "    return logB[y,:] + lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self, pi, A, B):\n",
    "        # p(x_0)\n",
    "        self.pi = pi\n",
    "        # p(x_k|x_{k-1})\n",
    "        self.A = A\n",
    "        # p(y_k|x_{k})\n",
    "        self.B = B\n",
    "        # Number of possible latent states at each time\n",
    "        self.S = pi.shape[0]\n",
    "        # Number of possible observations at each time\n",
    "        self.R = B.shape[0]\n",
    "        self.logB = np.log(self.B + 1e-100)\n",
    "        self.logA = np.log(self.A + 1e-100)\n",
    "        self.logpi = np.log(self.pi)\n",
    "        \n",
    "    def copy(self):\n",
    "        pi_ = self.pi.copy()\n",
    "        A_ = self.A.copy()\n",
    "        B_ = self.B.copy()\n",
    "        hmm = HMM(pi_,A_,B_)\n",
    "        return hmm\n",
    "    \n",
    "    def dump(self,filename='hmm.dump', format = '%.6f'):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write('%d\\n%d\\n' % (self.S,self.R))\n",
    "            for num in self.pi:\n",
    "                f.write((format+'\\n') % num)  \n",
    "            temp = self.A.reshape(np.product(self.A.shape), order='F')\n",
    "            for num in temp:\n",
    "                f.write((format+'\\n') % num)  \n",
    "            temp = self.B.reshape(np.product(self.B.shape), order='F')\n",
    "            for num in temp:\n",
    "                f.write((format+'\\n') % num)  \n",
    "    \n",
    "    @classmethod\n",
    "    def from_random_parameters(cls, S=3, R=5):\n",
    "        A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "        B = np.random.dirichlet(0.7*np.ones(R),S).T\n",
    "        pi = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "        return cls(pi, A, B)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_random_parameters_fixed_columns(cls, alphabet, S=5, R=20, V=2):\n",
    "        A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "        B = np.random.dirichlet(0.7*np.ones(R),S).T\n",
    "        pi = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "        vowels = ['a','e','ı','i','o','ö','u','ü']\n",
    "        ch2int = {c:i for i,c in enumerate(alphabet)}\n",
    "        ind = []\n",
    "        for v in vowels: \n",
    "            if v in ch2int.keys():\n",
    "                ind.append(ch2int[v])\n",
    "        mask = np.ones(R,dtype=bool)\n",
    "        mask[ind] = 0 # masks vowels\n",
    "        for c in range(V):\n",
    "            B[mask,c] = 0\n",
    "        for c in range(V,S):\n",
    "            B[ind,c] = 0\n",
    "        B = normalize(B,axis=0)\n",
    "        return cls(pi, A, B)\n",
    "    \n",
    "    def eval_lhood(self,y):\n",
    "        log_gamma = self.forward_backward_smoother(y)\n",
    "        return log_sum_exp(log_gamma[:,0])\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"Prior:\\n\" + str(self.pi) + \"\\nA:\\n\" + str(self.A) + \"\\nB:\\n\" + str(self.B)\n",
    "        return s\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = self.__str__()\n",
    "        return s\n",
    "\n",
    "    def predict(self, lp):\n",
    "        lstar = np.max(lp)\n",
    "        return lstar + np.log(np.dot(self.A,np.exp(lp-lstar)))\n",
    "\n",
    "    def postdict(self, lp):\n",
    "        lstar = np.max(lp)\n",
    "        return lstar + np.log(np.dot(np.exp(lp-lstar), self.A))\n",
    "\n",
    "    def update(self, y, lp):\n",
    "        return self.logB[y,:] + lp\n",
    "\n",
    "    def generate_sequence(self, T=10):\n",
    "        # T: Number of steps\n",
    "        x = np.zeros(T,dtype='int')\n",
    "        y = np.zeros(T,dtype='int')\n",
    "\n",
    "        for t in range(T):\n",
    "            if t==0:\n",
    "                x[t] = randgen(self.pi)\n",
    "            else:\n",
    "                x[t] = randgen(self.A[:,x[t-1]])    \n",
    "            y[t] = randgen(self.B[:,int(x[t])])\n",
    "    \n",
    "        return y, x\n",
    "\n",
    "    def forward(self, y):\n",
    "        T = len(y)\n",
    "        \n",
    "        # Forward Pass\n",
    "\n",
    "        # Python indexes starting from zero so\n",
    "        # log \\alpha_{k|k} will be in log_alpha[:,k-1]\n",
    "        # log \\alpha_{k|k-1} will be in log_alpha_pred[:,k-1]\n",
    "        log_alpha  = np.zeros((self.S, T))\n",
    "        log_alpha_pred = np.zeros((self.S, T))\n",
    "        for k in range(T):\n",
    "            if k==0:\n",
    "                log_alpha_pred[:,0] = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred[:,k] = self.predict(log_alpha[:,k-1])\n",
    "\n",
    "            log_alpha[:,k] = self.update(y[k], log_alpha_pred[:,k])\n",
    "            \n",
    "        return log_alpha, log_alpha_pred\n",
    "            \n",
    "    def backward(self, y):\n",
    "        # Backward Pass\n",
    "        T = len(y)\n",
    "        log_beta  = np.zeros((self.S, T))\n",
    "        log_beta_post = np.zeros((self.S, T))\n",
    "\n",
    "        for k in range(T-1,-1,-1):\n",
    "            if k==T-1:\n",
    "                log_beta_post[:,k] = np.zeros(self.S)\n",
    "            else:\n",
    "                log_beta_post[:,k] = self.postdict(log_beta[:,k+1])\n",
    "\n",
    "            log_beta[:,k] = self.update(y[k], log_beta_post[:,k])\n",
    "\n",
    "        return log_beta, log_beta_post\n",
    "        \n",
    "    def forward_backward_smoother(self, y):\n",
    "        log_alpha, log_alpha_pred = self.forward(y)\n",
    "        log_beta, log_beta_post = self.backward(y)\n",
    "        \n",
    "        log_gamma = log_alpha + log_beta_post\n",
    "        return log_gamma\n",
    "        \n",
    "    def correction_smoother(self, y):\n",
    "        # Correction Smoother\n",
    "\n",
    "        log_alpha, log_alpha_pred = self.forward(y)\n",
    "        T = len(y)\n",
    "        \n",
    "        # For numerical stability, we calculate everything in the log domain\n",
    "        log_gamma_corr = np.zeros_like(log_alpha)\n",
    "        log_gamma_corr[:,T-1] = log_alpha[:,T-1]\n",
    "\n",
    "        C2 = np.zeros((self.S, self.S))\n",
    "        C3 = np.zeros((self.R, self.S))\n",
    "        C3[y[-1],:] = normalize_exp(log_alpha[:,T-1], axis=None)\n",
    "        for k in range(T-2,-1,-1):\n",
    "            log_old_pairwise_marginal = log_alpha[:,k].reshape(1,self.S) + self.logA \n",
    "            log_old_marginal = self.predict(log_alpha[:,k])\n",
    "            log_new_pairwise_marginal = log_old_pairwise_marginal + log_gamma_corr[:,k+1].reshape(self.S,1) - log_old_marginal.reshape(self.S,1)\n",
    "            log_gamma_corr[:,k] = log_sum_exp(log_new_pairwise_marginal, axis=0).reshape(self.S)\n",
    "            C2 += normalize_exp(log_new_pairwise_marginal, axis=None)\n",
    "            C3[y[k],:] += normalize_exp(log_gamma_corr[:,k], axis=None)\n",
    "        C1 = normalize_exp(log_gamma_corr[:,0])\n",
    "        return C1, C2, C3, log_gamma_corr\n",
    "    \n",
    "    def forward_only_SS(self, y, V=None):\n",
    "        # Forward only estimation of expected sufficient statistics\n",
    "        T = len(y)\n",
    "        \n",
    "        if V is None:\n",
    "            V1  = np.eye((self.S))\n",
    "            V2  = np.zeros((self.S,self.S,self.S)) # s(a,b|x_k)\n",
    "            V3  = np.zeros((self.R,self.S,self.S))\n",
    "        else:\n",
    "            V1, V2, V3 = V\n",
    "            \n",
    "        I_S1S = np.eye(self.S).reshape((self.S,1,self.S))\n",
    "        I_RR = np.eye(self.R)\n",
    "        \n",
    "        for k in range(T):\n",
    "            if k==0:\n",
    "                log_alpha_pred = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred = self.predict(log_alpha)\n",
    "\n",
    "            if k>0:\n",
    "                # Calculate p(x_{k-1}|y_{1:k-1}, x_k) \n",
    "                lp = np.log(normalize_exp(log_alpha)).reshape(self.S,1) + self.logA.T    \n",
    "                P = normalize_exp(lp, axis=0)\n",
    "\n",
    "                # Update\n",
    "                V1 = np.dot(V1, P)             \n",
    "                V2 = np.dot(V2, P) + I_S1S*P.reshape((1,self.S,self.S))    \n",
    "                V3 = np.dot(V3, P) + I_RR[:,y[k-1]].reshape((self.R,1,1))*P.reshape((1,self.S,self.S))    \n",
    "\n",
    "            log_alpha = self.update(y[k], log_alpha_pred)    \n",
    "            p_xT = normalize_exp(log_alpha)    \n",
    "\n",
    "        C1 = np.dot(V1, p_xT.reshape(self.S,1))\n",
    "        C2 = np.dot(V2, p_xT.reshape(1,self.S,1)).reshape((self.S,self.S))\n",
    "        C3 = np.dot(V3, p_xT.reshape(1,self.S,1)).reshape((self.R,self.S))\n",
    "        C3[y[-1],:] +=  p_xT\n",
    "        \n",
    "        ll = log_sum_exp(log_alpha)\n",
    "        \n",
    "        return C1, C2, C3, ll, (V1, V2, V3)\n",
    "\n",
    "    \n",
    "    def train_EM(self, y, EPOCH=10, method='forward_only'):\n",
    "        LL = np.zeros(EPOCH)\n",
    "        params = []\n",
    "        for e in range(EPOCH):\n",
    "            params.append([self.pi,self.A,self.B])\n",
    "            if method is 'correction_smoother':\n",
    "                C1, C2, C3, log_gamma_corr = self.correction_smoother(y)\n",
    "                ll = log_sum_exp(log_gamma_corr[:,0])\n",
    "            elif method is 'forward_only':\n",
    "                C1, C2, C3, ll, V = self.forward_only_SS(y)\n",
    "            else:\n",
    "                return\n",
    "            LL[e] = ll\n",
    "            p = normalize(C1 + 1e-15, axis=0).reshape(self.S)\n",
    "            # print(p,np.size(p))            \n",
    "            A = normalize(C2, axis=0)\n",
    "            # print(A)\n",
    "            B = normalize(C3, axis=0)\n",
    "            # print(B)\n",
    "            self.__init__(p, A, B)\n",
    "            \n",
    "        return LL, params\n",
    "    \n",
    "    \n",
    "    def online_em(self, y, V=None, n_min=100, gamma=0.2,log_interval=1e4, learn_rate=-0.6, update_freq=1):\n",
    "        T = len(y)\n",
    "        LL = np.zeros(T)\n",
    "        params = []\n",
    "        \n",
    "        if V is None:\n",
    "            V1  = np.eye((self.S))\n",
    "            V2  = np.zeros((self.S,self.S,self.S)) # s(x_k,x_{k-1}|x_k)\n",
    "            V3  = np.zeros((self.R,self.S,self.S))\n",
    "        else:\n",
    "            V1, V2, V3 = V\n",
    "            \n",
    "        I_S1S = np.eye(self.S).reshape((self.S,1,self.S))\n",
    "        I_RR = np.eye(self.R)\n",
    "        \n",
    "        for k in range(T):\n",
    "            # save model params\n",
    "            if np.mod(k,log_interval)==0: \n",
    "                params.append([self.pi,self.A,self.B])\n",
    "                # log_gamma = self.forward_backward_smoother(y)\n",
    "            # E step\n",
    "            if k==0:\n",
    "                log_alpha_pred = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred = self.predict(log_alpha)\n",
    "\n",
    "            if k>0:\n",
    "                # Calculate p(x_{k-1}|y_{1:k-1}, x_k) \n",
    "                lp = np.log(normalize_exp(log_alpha)).reshape(self.S,1) + self.logA.T    \n",
    "                P = normalize_exp(lp, axis=0)\n",
    "\n",
    "                # Update\n",
    "                V1 = np.dot(V1, P)             \n",
    "                V2 = (1-gamma)*np.dot(V2, P) + gamma*I_S1S*P.reshape((1,self.S,self.S))    \n",
    "                V3 = (1-gamma)*np.dot(V3, P) + gamma*I_RR[:,y[k-1]].reshape((self.R,1,1))*P.reshape((1,self.S,self.S))    \n",
    "                \n",
    "                \n",
    "            log_alpha = self.update(y[k], log_alpha_pred)    \n",
    "                \n",
    "            p_xT = normalize_exp(log_alpha)    \n",
    "        \n",
    "            LL[k] = log_sum_exp(log_alpha)\n",
    "            \n",
    "            # M step\n",
    "            if k > n_min:\n",
    "                C1 = np.dot(V1, p_xT.reshape(self.S,1))\n",
    "                C2 = np.dot(V2, p_xT.reshape(1,self.S,1)).reshape((self.S,self.S))\n",
    "                C3 = np.dot(V3, p_xT.reshape(1,self.S,1)).reshape((self.R,self.S))\n",
    "                C3[y[k],:] +=  p_xT\n",
    "                \n",
    "                p = normalize(C1 + 0.1, axis=0).reshape(self.S)\n",
    "                A = normalize(C2, axis=0)\n",
    "                B = normalize(C3, axis=0)\n",
    "                self.__init__(p, A, B)\n",
    "            if np.mod(k,update_freq)==0:\n",
    "                gamma = np.power(k,learn_rate)\n",
    "    \n",
    "        return LL,params\n",
    "\n",
    "    \n",
    "    def forward_only_SS_c(self, y, log_alpha=None, V=None):\n",
    "        # Forward only estimation of expected sufficient statistics\n",
    "        T = len(y)\n",
    "        \n",
    "        if V is None:\n",
    "            V1  = np.eye((self.S))\n",
    "            V2  = np.zeros((self.S,self.S,self.S))\n",
    "            V3  = np.zeros((self.R,self.S,self.S))\n",
    "        else:\n",
    "            V1, V2, V3 = V\n",
    "            \n",
    "        I_S1S = np.eye(self.S).reshape((self.S,1,self.S))\n",
    "        I_RR = np.eye(self.R)\n",
    "        \n",
    "        for k in range(T):\n",
    "            if log_alpha is None:\n",
    "                log_alpha_pred = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred = self.predict(log_alpha)\n",
    "                \n",
    "            # Update\n",
    "            if k > 0:\n",
    "                # Calculate p(x_{k-1}|y_{1:k-1}, x_k) \n",
    "                lp = np.log(normalize_exp(log_alpha)).reshape(self.S,1) + self.logA.T    \n",
    "                P = normalize_exp(lp, axis=0)\n",
    "                \n",
    "                V1 = np.dot(V1, P)             \n",
    "                V2 = np.dot(V2, P) + I_S1S*P.reshape((1,self.S,self.S)) \n",
    "                V3 = np.dot(V3, P) + I_RR[:,y[k-1]].reshape((self.R,1,1))*P.reshape((1,self.S,self.S))   \n",
    "\n",
    "            log_alpha = self.update(y[k], log_alpha_pred)    \n",
    "            p_xT = normalize_exp(log_alpha)    \n",
    "\n",
    "        C1 = np.dot(V1, p_xT.reshape(self.S,1))\n",
    "        C2 = np.dot(V2, p_xT.reshape(1,self.S,1)).reshape((self.S,self.S))\n",
    "        C3 = np.dot(V3, p_xT.reshape(1,self.S,1)).reshape((self.R,self.S))\n",
    "        C3[y[-1],:] +=  p_xT\n",
    "        \n",
    "        return C1, C2, C3, V1, V2, V3, log_alpha\n",
    "    \n",
    "    \n",
    "    \n",
    "    def online_em_c(self, y, V=None, n_min=100, gamma=0.2,log_interval=1e4, learn_rate=-0.80):\n",
    "        T = len(y)\n",
    "        LL = np.zeros(T)\n",
    "        params = []\n",
    "        \n",
    "        C1  = np.zeros(self.S)\n",
    "        C2  = np.zeros((self.S,self.S))\n",
    "        C3  = np.zeros((self.R,self.S))\n",
    "            \n",
    "        I_S1S = np.eye(self.S).reshape((self.S,1,self.S))\n",
    "        I_RR = np.eye(self.R)\n",
    "        \n",
    "        for k in range(T):\n",
    "            # save model params\n",
    "            if np.mod(k,log_interval)==0: \n",
    "                params.append([self.pi,self.A,self.B])\n",
    "            # E step\n",
    "            if k==0:\n",
    "                log_alpha_pred = self.logpi\n",
    "                log_alpha = self.update(0, log_alpha_pred)  \n",
    "            else:\n",
    "                # calculate sufficient states\n",
    "                C1_fb, C2_fb, C3_fb, V1_fb, V2_fb, V3_fb, log_alpha = self.forward_only_SS_c(y[k],log_alpha)\n",
    "                C1 = (1-gamma)*C1 + gamma*C1_fb.reshape(self.S)            \n",
    "                C2 = (1-gamma)*C2 + gamma*C2_fb   \n",
    "                C3 = (1-gamma)*C3 + gamma*C3_fb  \n",
    "                \n",
    "            # M step\n",
    "            if k > n_min:\n",
    "                p = normalize(C1 + 0.1, axis=0)\n",
    "                A = normalize(C2, axis=0)\n",
    "                B = normalize(C3, axis=0)\n",
    "                self.__init__(p, A, B)\n",
    "                gamma = np.min((0.2,np.power(k,learn_rate)))\n",
    "    \n",
    "        return LL,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL of the generative model is -199.3272\n",
      "Results with the Forward Smoother\n",
      "[[ 0.43789118]\n",
      " [ 0.03841169]\n",
      " [ 0.52369713]]\n",
      "1.0\n",
      "\n",
      "\n",
      "[[  4.49100582e+00   3.16736247e+01   1.80143816e-02]\n",
      " [  4.19228411e+00   2.22532459e+00   2.82341730e+01]\n",
      " [  2.71133566e+01   6.16970510e-01   4.35246231e-01]]\n",
      "99.0\n",
      "\n",
      "\n",
      "[[  5.09217392e+00   2.46047384e-01   5.66177870e+00]\n",
      " [  7.67070445e-01   1.53427288e+00   8.69865667e+00]\n",
      " [  5.53564027e-03   4.95620706e+00   1.03825730e+00]\n",
      " [  7.66488244e-01   9.27661087e-04   2.32584095e-01]\n",
      " [  7.00865696e-01   6.42862982e+00   7.87050448e+00]\n",
      " [  2.17970980e+01   1.87342252e+00   3.29479479e-01]\n",
      " [  1.77656681e+00   9.13129635e-01   1.31030355e+00]\n",
      " [  2.15241176e+00   1.00499656e+01   7.97622645e-01]\n",
      " [  2.64124348e+00   6.96216218e+00   1.39659434e+00]\n",
      " [  9.21082139e-01   1.72542865e+00   1.35348921e+00]]\n",
      "100.0\n",
      "\n",
      "\n",
      "Results with the Correction Smoother\n",
      "[ 0.43789118  0.03841169  0.52369713]\n",
      "1.0\n",
      "\n",
      "\n",
      "[[  4.49100582e+00   3.16736247e+01   1.80143816e-02]\n",
      " [  4.19228411e+00   2.22532459e+00   2.82341730e+01]\n",
      " [  2.71133566e+01   6.16970510e-01   4.35246231e-01]]\n",
      "99.0\n",
      "\n",
      "\n",
      "[[  5.09217392e+00   2.46047384e-01   5.66177870e+00]\n",
      " [  7.67070445e-01   1.53427288e+00   8.69865667e+00]\n",
      " [  5.53564027e-03   4.95620706e+00   1.03825730e+00]\n",
      " [  7.66488244e-01   9.27661087e-04   2.32584095e-01]\n",
      " [  7.00865696e-01   6.42862982e+00   7.87050448e+00]\n",
      " [  2.17970980e+01   1.87342252e+00   3.29479479e-01]\n",
      " [  1.77656681e+00   9.13129635e-01   1.31030355e+00]\n",
      " [  2.15241176e+00   1.00499656e+01   7.97622645e-01]\n",
      " [  2.64124348e+00   6.96216218e+00   1.39659434e+00]\n",
      " [  9.21082139e-01   1.72542865e+00   1.35348921e+00]]\n",
      "100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM.from_random_parameters(S=3,R=10)\n",
    "\n",
    "L = 100\n",
    "\n",
    "y,x = hmm.generate_sequence(L)\n",
    "log_gamma = hmm.forward_backward_smoother(y)\n",
    "\n",
    "print(\"LL of the generative model is {:.4f}\".format(log_sum_exp(log_gamma[:,0])[0]))\n",
    "\n",
    "print(\"Results with the Forward Smoother\")\n",
    "C1, C2, C3, ll, V = hmm.forward_only_SS(y)\n",
    "\n",
    "print(C1)\n",
    "print(np.sum(C1))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(C2)\n",
    "print(np.sum(C2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(C3)\n",
    "print(np.sum(C3))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Results with the Correction Smoother\")\n",
    "C1_corr, C2_corr, C3_corr, lg = hmm.correction_smoother(y)\n",
    "\n",
    "print(C1_corr)\n",
    "print(np.sum(C1_corr))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(C2_corr)\n",
    "print(np.sum(C2_corr))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(C3_corr)\n",
    "print(np.sum(C3_corr))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-220.01193816 -211.8252658  -211.54451451 -211.36415375 -211.21140326\n",
      " -211.05586755 -210.88428884 -210.6952732  -210.49534031 -210.29228465\n",
      " -210.09043223 -209.89081441 -209.69369014 -209.50040879 -209.31389516\n",
      " -209.13818328 -208.97738864 -208.83441858 -208.70992552 -208.60202209\n",
      " -208.50680564 -208.41923255 -208.33383582 -208.24509612 -208.14757532\n",
      " -208.0360312  -207.90569424 -207.75276622 -207.57502587 -207.37227166\n",
      " -207.14636309 -206.90095161 -206.64140454 -206.37539977 -206.11389053\n",
      " -205.87101757 -205.66135572 -205.49492446 -205.37341478 -205.29085636\n",
      " -205.2377218  -205.20481536 -205.18500677 -205.1733315  -205.16652102\n",
      " -205.16250479 -205.1600143  -205.15829136 -205.15688484 -205.15551713\n",
      " -205.15400081 -205.15218827 -205.14994117 -205.1471112  -205.14352675\n",
      " -205.13898285 -205.13323329 -205.12598491 -205.11689582 -205.10557998\n",
      " -205.09162247 -205.07461096 -205.0541893  -205.03013709 -205.00247239\n",
      " -204.97156157 -204.9382022  -204.90363012 -204.86940719 -204.83718437\n",
      " -204.80839821 -204.78400805 -204.76437245 -204.74929577 -204.7381971\n",
      " -204.73031579 -204.72488211 -204.72122199 -204.71879915 -204.71721506\n",
      " -204.71618781 -204.71552491 -204.71509814 -204.71482358 -204.71464686\n",
      " -204.71453297 -204.71445947 -204.71441195 -204.71438118 -204.71436123\n",
      " -204.71434827 -204.71433985 -204.71433436 -204.71433079 -204.71432846\n",
      " -204.71432694 -204.71432595 -204.7143253  -204.71432488 -204.7143246 ]\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM.from_random_parameters(S=3,R=10)\n",
    "y,x = hmm.generate_sequence(100)\n",
    "\n",
    "LL, params = hmm.train_EM(y, 100)\n",
    "print(LL)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
