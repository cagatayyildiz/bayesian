{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run include/utils.py\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def draw_points(X, N1, xlim_, ylim_, title_='', W=None):\n",
    "    plt.figure()\n",
    "    plt.plot(X[:N1,0],X[:N1,1], 'b+')\n",
    "    plt.plot(X[N1:,0],X[N1:,1], 'r*')\n",
    "    plt.title(title_)\n",
    "    plt.xlim(xlim_)\n",
    "    plt.ylim(ylim_)\n",
    "    \n",
    "    if W is not None:\n",
    "        x_ = np.arange(np.min(X),np.max(X),1e-2)\n",
    "        y_ = (-x_*W[1]-W[0])/W[2]\n",
    "        plt.plot(x_, y_, 'm-')\n",
    "        \n",
    "def gen_data_gauss(N1=50, N2=50, N3=50, draw=False,\n",
    "                  center1 = np.array([2,8]),\n",
    "                  center2 = np.array([5,5]),\n",
    "                  center3 = np.array([8,2]),\n",
    "                  var1 = np.array([1.2,1,1,1.2]).reshape((2,2)),\n",
    "                  var2 = np.array([1.2,1,1,1.2]).reshape((2,2)),\n",
    "                  var3 = np.array([1.0,1,1,1.0]).reshape((2,2))):\n",
    "    # data stay in rows\n",
    "    S1 = np.random.multivariate_normal(center1,var1,(N1))\n",
    "    S2 = np.random.multivariate_normal(center2,var2,(N2))\n",
    "    S3 = np.random.multivariate_normal(center3,var3,(N3))\n",
    "    S1 = np.vstack((S1,S2))\n",
    "    N1 = N1+N2\n",
    "    # data matrix\n",
    "    X = np.vstack((S1,S3))\n",
    "    R = np.hstack((np.ones(len(S1)),-1*np.ones(len(S2))))\n",
    "    if draw:\n",
    "        draw_points(X, N1, [-2,12], [-2,12], title_=\"data points\")\n",
    "    return X, R, N1, N2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "- Indices:\n",
    "  - $n$ over samples\n",
    "  - $m$ over data dimensions\n",
    "  - $k$ over groups\n",
    "\n",
    "\n",
    "- Samples: \n",
    "  - $(x_n, y_n)$ \n",
    "  - $n \\in \\{1,\\ldots,N\\}$\n",
    "  - $x_n \\in \\mathcal{R}^M$\n",
    "  - $y_n \\in \\{-1,1\\}$\n",
    "  - For notational conveince, set $x_n := [1, x_n^T]^T$. Now, $x_n \\in \\mathcal{R}^{M+1}$\n",
    "  - Data stored in the **columns** of an $(M+1)\\times N$ dimensional matrix $\\mathbf{X}$ and class labels in $\\mathbf{y} \\in \\mathcal{R}^N$.\n",
    "  - So, $x_{m,n}$ is the value of the $m$'th dimension of the $n$ sample.\n",
    "  \n",
    "  \n",
    " - Weights:\n",
    "  - First, define $K$ to be the number of groups, a fixed number.\n",
    "  - Weights stored in the **rows** of an $K\\times(M+1)$ dimensional matrix $\\mathbf{W}$.\n",
    "  - So, $w_{k,m}$ is the weight for the $m$'th dimension in $k$'th group.\n",
    "  \n",
    "  \n",
    " - Group probabilities (latent, not necassarily normalized):\n",
    "  - The group probability of $x_n$ is stored in $n$'th the **row** of an $N \\times K$ dimensional matrix $\\mathbf{Z}$.\n",
    "  - So, $z_{n,k}$ is the (unnormalized) probability of the $n$'th sample being in $k$'th group.\n",
    "  \n",
    "#### The risk for $n$'th sample:\n",
    "\\begin{align}\n",
    "\\hat{y}(x_n) &= \\sum_{k=1}^K z_{n,k} \\left( \\sum_{m=0}^M w_{k,m}x_{m,n} \\right) \\\\\n",
    "&= \\sum_{k=1}^K z_{n,k} \\mathbf{X}[:,n] \\mathbf{W}[k,:]\n",
    "\\end{align}\n",
    "\n",
    "#### The overall risk:\n",
    "\\begin{align}\n",
    "\\text{risk}(\\hat{y}; \\mathbf{X}, \\mathbf{y}) = -\\sum_{n=1}^N y_n \\hat{y}(x_n) \n",
    "\\end{align}\n",
    "\n",
    "#### Regularization:\n",
    "\\begin{align}\n",
    "r_z &= \\sum_{k=1}^K \\sum_{n=1}^N z_{n,k} \\log(z_{n,k}) \\\\\n",
    "r_w &= \\sum_{k=1}^K \\sum_{m=1}^M w_{k,m}^2\n",
    "\\end{align}\n",
    "\n",
    "### The objective function:\n",
    "\\begin{align}\n",
    "f(\\mathbf{W},\\mathbf{Z}; \\mathbf{X}, \\mathbf{y}) = -\\sum_{n=1}^N y_n \\left( \\sum_{k=1}^K z_{n,k} \\left( \\sum_{m=0}^M w_{k,m}x_{m,n} \\right) \\right) + \\lambda \\sum_{k=1}^K \\sum_{n=1}^N z_{n,k} \\log(z_{n,k}) + \\mu \\sum_{k=1}^K \\sum_{m=1}^M w_{k,m}^2\n",
    "\\end{align}\n",
    "\n",
    "### Partial derivatives\n",
    "We now need partial derivatives for the optimization parameters: $w_{k,m}$ and $z_{n,k}$\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial w_{k,m}} &= -\\sum_{n=1}^N y_n x_{m,n} z_{n,k} + 2\\mu w_{k,m} \\\\\n",
    "\\frac{\\partial f}{\\partial z_{n,k}} &= -y_n \\sum_{m=0}^M w_{k,m}x_{m,n} + \\lambda(\\log z_{n,k} +1)\n",
    "\\end{align}\n",
    "Because the objective is minimization, we move in the negative direction of the gradient: $w_{k,m} := w_{k,m} - \\frac{\\partial f}{\\partial w_{k,m}}$ and $z_{n,k} := z_{n,k}-\\frac{\\partial f}{\\partial z_{n,k}}$\n",
    "\n",
    "### The learning algorithm:\n",
    "- Indices:\n",
    "  - N: number of samples\n",
    "  - M: dimensionality\n",
    "  - K: number of groups \n",
    "- Initialize \n",
    "  - $\\mathbf{W} \\in K\\times(M+1)$\n",
    "  - $\\mathbf{Z} \\in N \\times K$\n",
    "- Set \n",
    "  - $x_n:= [1, x_n^T]^T$ for all $n\\in \\{1,\\ldots,N\\}$\n",
    "  - learning rate $\\eta=0.01$\n",
    "  - regularizer for group parameters $\\lambda=0.01$\n",
    "  - regularizer for weights $\\mu=0.01$\n",
    "- Iterate until convergence\n",
    "\\begin{align}\n",
    "w_{k,m} &:= w_{k,m} + \\eta\\left( \\sum_{n=1}^N y_n x_{m,n} z_{n,k} - 2\\mu w_{k,m}[m \\neq 0] \\right) \\\\\n",
    "z_{n,k} &:= z_{n,k} + \\eta\\left( y_n \\sum_{m=0}^M w_{k,m}x_{m,n} - \\lambda(\\log z_{n,k} +1) \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "2\n",
      "3\n",
      "[[ 4.20476271  2.34965321  0.80710398]\n",
      " [ 3.00266085 -0.77594158  0.93970313]\n",
      " [ 2.89758021 -2.91020501  0.59825153]]\n",
      "[[ 7.65406888  5.68293584  0.80710398]\n",
      " [ 5.47986227 -2.28126757  0.93970313]\n",
      " [ 4.87229842 -7.82699205  0.59825153]]\n",
      "[[        nan         nan  0.80710398]\n",
      " [ 7.8689572  -4.45605108  0.93970313]\n",
      " [        nan         nan  0.59825153]]\n",
      "[[        nan         nan  0.80710398]\n",
      " [ 7.8689572  -4.45605108  0.93970313]\n",
      " [        nan         nan  0.59825153]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nek4SeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f068ec1be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y, N1, N2 = gen_data_gauss()\n",
    "[N,M] = X.shape\n",
    "K = 3\n",
    "MAX_ITER = 3\n",
    "eta = 0.01\n",
    "lamb = 0.001\n",
    "mu = 0.1\n",
    "print(N)\n",
    "print(M)\n",
    "print(K)\n",
    "\n",
    "X = np.hstack((np.ones(N1+N2).reshape((-1,1)),X)).transpose() # M+1 x N\n",
    "W = np.random.random((K,M+1))\n",
    "Z = np.random.random((N,K))*10\n",
    "\n",
    "for s in range(MAX_ITER):\n",
    "    for k in range(K):\n",
    "        for m in range(M):\n",
    "            tmp = 0\n",
    "            for n in range(N):\n",
    "                tmp += X[m,n]*Z[n,k]*Y[n]\n",
    "            W[k,m] = W[k,m] + eta*(tmp-2*mu*W[k,m]*(m!=0))\n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            tmp = 0\n",
    "            for m in range(M):\n",
    "                tmp += W[k,m]*X[m,n]*Y[n]\n",
    "            Z[n,k] = Z[n,k] + eta*(tmp-lamb*(np.log(Z[n,k])+1))\n",
    "            Z[n,k] = Z[n,k]*(Z[n,k]<0) + Z[n,k]*(Z[n,k]>0)\n",
    "    print(W)\n",
    "            \n",
    "print(W)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X[1,:N1],X[2,:N1], 'b+')\n",
    "plt.plot(X[1,N1:],X[2,N1:], 'r*')\n",
    "plt.xlim([-2,12])\n",
    "plt.ylim([-2,12])\n",
    "for k in range(K):\n",
    "    x_ = np.arange(np.min(X),np.max(X),1e-2)\n",
    "    y_ = (-x_*W[k,1]-W[k,0])/W[k,2]\n",
    "    plt.plot(x_, y_, 'm-')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65123 samples, each 123 dimensional.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from scipy import sparse\n",
    "[X,y] = load_svmlight_file(\"data/A9A\")\n",
    "[L, N] = X.shape\n",
    "print(str(L) + \" samples, each \" + str(N) + \" dimensional.\")\n",
    "\n",
    "C = 20\n",
    "L1_SVM = 1\n",
    "if L1_SVM:\n",
    "    U = C\n",
    "else:\n",
    "    U = 1e10\n",
    "RESULT_FOLDER = \"data/weights/\"\n",
    "MAX_ITER = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169,)\n",
      "(1169,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-eb80557bcf93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mQii\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_ITER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "alpha = np.zeros((1,L))\n",
    "w0 = 0\n",
    "w = np.zeros((1,N))\n",
    "\n",
    "Qii = np.zeros(L)\n",
    "for l in range(L):\n",
    "    tmp = x_*x_.T\n",
    "    print(tmp.shape)\n",
    "    Qii[l] = tmp[0,0]\n",
    "\n",
    "for it in range(MAX_ITER):\n",
    "    now_ = time.time()\n",
    "    for i in range(L):\n",
    "        # step-1\n",
    "        x_ = X[i,:].todense().reshape(N)\n",
    "        G = (y[i]*x_*w.T - 1)[0,0] + (1-L1_SVM)/(2*C) \n",
    "        # step-2\n",
    "        if alpha[0,i]==0:\n",
    "            PG = np.min(G,0)\n",
    "        elif alpha[0,i] == U:\n",
    "            PG = np.max(G,0)\n",
    "        elif 0<alpha[0,i] and alpha[0,i]<U:\n",
    "            PG = G\n",
    "        # step-3\n",
    "        if np.abs(PG)!=0:\n",
    "            alpha_old = alpha[0,i]\n",
    "            # Qii = (x_*x_.T)[0,0]\n",
    "            alpha[0,i] = min(max(alpha[0,i]-G/Qii[i],0),U)\n",
    "            w = w + (alpha[0,i]-alpha_old)*y[i]*x_\n",
    "            w0 = w0 + (alpha[0,i]-alpha_old)*y[i] \n",
    "    w_ = np.hstack((w,np.array(w0).reshape((1,1))))\n",
    "    np.savetxt(RESULT_FOLDER+\"w\"+str(it)+\".txt\",w_)\n",
    "    print(\"iteration: \" + str(it) + \", duration: \" + str(int(time.time()-now_)) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = []\n",
    "w_old = np.loadtxt(RESULT_FOLDER+\"w0.txt\")\n",
    "for i in range(1,MAX_ITER):\n",
    "    w = np.loadtxt(RESULT_FOLDER+\"w\"+str(i)+\".txt\")\n",
    "    diff_ = np.abs(np.sum(w-w_old))/len(w)\n",
    "    diff.append(diff_)\n",
    "    w_old = w\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(diff, '*-b')\n",
    "plt.xlabel(\"iteration number\")\n",
    "plt.ylabel(\"the change in weights (per weight)\")\n",
    "plt.ylim([0,np.max(diff)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print and plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "for it in range(MAX_ITER):\n",
    "    w_ = np.loadtxt(RESULT_FOLDER+\"w\"+str(it)+\".txt\")\n",
    "    w0 = w_[-1]\n",
    "    w = w_[:-2] # ignore the last weight and omit w0 appended at the end of w \n",
    "\n",
    "    # load the data set\n",
    "    [Xt,yt] = load_svmlight_file(\"data/A9A.t\")\n",
    "    [Lt, Nt] = Xt.shape\n",
    "    y_res = np.zeros(Lt)\n",
    "\n",
    "    # compute my results\n",
    "    for i in range(Lt):\n",
    "        y_res[i] = (Xt[i]*w)[0]+w0\n",
    "\n",
    "    acc_ = 1-np.sum(np.array(yt*y_res)<0)/len(y_res)\n",
    "    acc.append(acc_)\n",
    "    print(\"accuracy: \" + str(acc_))\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(acc, '*-b')\n",
    "plt.xlabel(\"iteration number\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim([np.min(acc),np.max(acc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Clustering the data to start with good initial $K$ and $\\mathbf{Z}$ values.\n",
    " - k-fold cross validation for model parameters\n",
    " - linear regression but with basis functions\n",
    " - Do not compute gradient if $x_{n,m}$ is zero\n",
    " - What ensures the positivity of $z_{n,k}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
